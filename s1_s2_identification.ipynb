{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Working_ID_Face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_Wxj6n0c5hddX5hcMwTbRf-McMfK_rqZ",
      "authorship_tag": "ABX9TyNokHTH7IpD3k88JbClUKFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kckiran01/CSC550/blob/master/s1_s2_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY2b8WBDfuco",
        "outputId": "3aca7196-d08b-4ced-8cc5-02990fda5c7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir='/content/drive/MyDrive/csc591_avg/train_swipeLeft'\n",
        "test_dir='/content/drive/MyDrive/csc591_avg/test_swipeLeft'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzF5WVNdimW0"
      },
      "source": [
        "You should rescale your data as dividing 1/255 to transform your pixel value from a range [0,255 ] to [0,1] to behave all images the same. After that, you can flow your images from their directories by specifying some parameters. The target size parameter helps you to resize your image as you specified. If you have two classes you should set the class mode parameter as “binary”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxFGahhg0xP",
        "outputId": "f3a6b9f6-e32d-4768-a6b8-1abeec87542a"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#All images will be rescaled by 1./255 which may not necessary in our case though...Kiran\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # This is the cource directory for training images\n",
        "    target_size=(256,256), # All images will be resized..not sure if this is necessary--- Kiran\n",
        "    batch_size = 20,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Flow validation images in batches of 8 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (256,256),\n",
        "    batch_size=10,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 600 images belonging to 30 classes.\n",
            "Found 600 images belonging to 30 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrkDQtjGjHVw"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(256,256,3)),\n",
        "                                    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(20, activation = 'relu'),\n",
        "                                    tf.keras.layers.Dense(30, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A6SQHGqlRii",
        "outputId": "56660cdc-f682-4c52-b090-549ff03fa0a5"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.summary()\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=20, #total images = batch_size * steps--kiran\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20 # total images = batch_size * steps--kiran\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 254, 254, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 252, 252, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 126, 126, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 124, 124, 32)      4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 122, 122, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 119072)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                2381460   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 30)                630       \n",
            "=================================================================\n",
            "Total params: 2,398,746\n",
            "Trainable params: 2,398,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "20/20 [==============================] - 110s 4s/step - loss: 3.3805 - accuracy: 0.0600 - val_loss: 3.3944 - val_accuracy: 0.0100\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 17s 866ms/step - loss: 3.2893 - accuracy: 0.0825 - val_loss: 3.3527 - val_accuracy: 0.0250\n",
            "Epoch 3/30\n",
            "13/20 [==================>...........] - ETA: 2s - loss: 3.2229 - accuracy: 0.0885"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0j50g6DnsPl"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, precision_score\n",
        "Y_pred = model.predict_generator(validation_generator,60) # class is 30, so put 29\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(Y_pred)\n",
        "print('y pred >>> ')\n",
        "print(y_pred)\n",
        "#print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "print('classfication report')\n",
        "print(str(np.mean(recall_score(validation_generator.classes, y_pred, average=None))))\n",
        "accuracy =(accuracy_score(validation_generator.classes, y_pred))*100\n",
        "print(str(accuracy))\n",
        "prec= np.mean(precision_score(validation_generator.classes, y_pred, average=None))*100\n",
        "print(str(prec))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}